{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c1cb34",
   "metadata": {},
   "source": [
    "# MSA 2024 Phase 2 - Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa5f79",
   "metadata": {},
   "source": [
    "Welcome to the competition - in Part 3, you are encouraged to utilize neural network based models for classification.\n",
    "\n",
    "This notebook builds a simple Multi-Layer Perceptron (MLP) model for the CIFAR-10 dataset, with the use of `keras` to define the model structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1c5d8",
   "metadata": {},
   "source": [
    "**Before start working on the competition, please ensure all required libraries are installed and properly set up on your system**:\n",
    "\n",
    "- `python >= 3.6`,\n",
    "- `tensorFlow >= 2.0`,\n",
    "- `keras >= 2.3`,\n",
    "\n",
    "and any neccassary liburaries for data manipulation and processing, e.g., `numpy`, `pandas`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d550cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85f3a2",
   "metadata": {},
   "source": [
    "### 1. Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49efe468",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset contains 60,000 images(32x32x3) in 10 different classes, with 6,000 images in each class. You can download the dataset directly from the competition webpage.\n",
    "\n",
    "**To train the model, you are expected to use the training label provided in train.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d0bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dir = 'D:\\\\mslearn-phase2\\\\msa-phase2\\\\Deep Learning\\\\train'\n",
    "# D:\\mslearn-phase2\\msa-phase2\\Deep Learning\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "def loadTrain(root_dir, csv_file):\n",
    "    ids = []\n",
    "    images = []\n",
    "    labels = []\n",
    "    annotations = np.genfromtxt('train.csv', delimiter=',', names=True)\n",
    "    for idx in range(0, len(annotations)):\n",
    "        img_id = int(annotations['id'][idx])\n",
    "        img_name = os.path.join(root_dir, f\"image_{img_id}.png\")\n",
    "        image = np.array(Image.open(img_name).convert(\"RGB\"))\n",
    "        label = int(annotations['label'][idx])\n",
    "\n",
    "        ids.append(img_id)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    return np.array(ids), np.array(images), np.array(labels)\n",
    "\n",
    "def loadTest(root_dir):\n",
    "    ids = []\n",
    "    images = []\n",
    "    for idx in range(len(os.listdir(root_dir))):\n",
    "        img_name = os.path.join(root_dir, f\"image_{idx}.png\")\n",
    "        image = np.array(Image.open(img_name).convert(\"RGB\"))\n",
    "\n",
    "        ids.append(idx)\n",
    "        images.append(image)\n",
    "    return np.array(ids), np.array(images)\n",
    "\n",
    "\n",
    "# Load training, testing data and the training label provided in train.csv.\n",
    "train_csv = 'train.csv'\n",
    "id_train, X_train, y_train = loadTrain(train_dir, train_csv)\n",
    "id_test, X_test = loadTest(test_dir)\n",
    "\n",
    "# Normalize the data. Reshape the data to fit in to an MLP model.\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "cnn_x_train = X_train\n",
    "cnn_x_test = X_test\n",
    "\n",
    "X_train = X_train.reshape(-1, 3072)\n",
    "X_test = X_test.reshape(-1, 3072)\n",
    "\n",
    "# Applying the function to training set labels and testing set labels \n",
    "from keras.utils import to_categorical \n",
    "\n",
    "# Convert training labels to one-hot encoded vectors.\n",
    "y_train_vec = to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ae9e8",
   "metadata": {},
   "source": [
    "### 2. Build & train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3f0331",
   "metadata": {},
   "source": [
    "This code demostrates a simple Multi-Layer Perceptron (MLP) model. However, you are encouraged to experiment with more complex deep learning models and techniques to boost your performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d60add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mslearn-phase2\\msa\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1684 - loss: 2.2051 - val_accuracy: 0.2667 - val_loss: 1.9825\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2740 - loss: 1.9649 - val_accuracy: 0.2741 - val_loss: 1.9499\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3034 - loss: 1.9029 - val_accuracy: 0.2911 - val_loss: 1.9516\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3150 - loss: 1.8847 - val_accuracy: 0.3101 - val_loss: 1.8854\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3281 - loss: 1.8465 - val_accuracy: 0.2955 - val_loss: 1.9313\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3301 - loss: 1.8376 - val_accuracy: 0.3200 - val_loss: 1.8816\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3296 - loss: 1.8343 - val_accuracy: 0.3196 - val_loss: 1.8457\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3354 - loss: 1.8204 - val_accuracy: 0.3522 - val_loss: 1.8099\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3438 - loss: 1.8136 - val_accuracy: 0.3255 - val_loss: 1.8636\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3429 - loss: 1.8012 - val_accuracy: 0.3317 - val_loss: 1.8437\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Model initialization.\n",
    "model = tf.keras.Sequential()\n",
    " \n",
    "# Build the MLP model.\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10,  activation=\"softmax\"))\n",
    "\n",
    "# Complile the model.\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model.\n",
    "model.fit(X_train, y_train_vec, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Prepare your submission file.\n",
    "submission = np.column_stack((id_test, predicted_labels))\n",
    "np.savetxt('submission.csv', submission, delimiter=',', header='id, Label', comments='', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6da20",
   "metadata": {},
   "source": [
    "### 3. Build my Own Custom Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d1bd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.32156864, 0.34901962, 0.32156864],\n",
       "         [0.32156864, 0.34901962, 0.32156864],\n",
       "         [0.3254902 , 0.3529412 , 0.3254902 ],\n",
       "         ...,\n",
       "         [0.41960785, 0.44705883, 0.46666667],\n",
       "         [0.4117647 , 0.44705883, 0.46666667],\n",
       "         [0.44705883, 0.48235294, 0.5019608 ]],\n",
       "\n",
       "        [[0.33333334, 0.36078432, 0.33333334],\n",
       "         [0.31764707, 0.34509805, 0.31764707],\n",
       "         [0.31764707, 0.34509805, 0.31764707],\n",
       "         ...,\n",
       "         [0.4117647 , 0.4509804 , 0.46666667],\n",
       "         [0.38039216, 0.41568628, 0.43529412],\n",
       "         [0.4117647 , 0.44705883, 0.46666667]],\n",
       "\n",
       "        [[0.32941177, 0.36078432, 0.32941177],\n",
       "         [0.3254902 , 0.3529412 , 0.3254902 ],\n",
       "         [0.32941177, 0.35686275, 0.32941177],\n",
       "         ...,\n",
       "         [0.45490196, 0.49411765, 0.50980395],\n",
       "         [0.4392157 , 0.4745098 , 0.49411765],\n",
       "         [0.47058824, 0.5058824 , 0.5254902 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.47843137, 0.4       , 0.3019608 ],\n",
       "         [0.46666667, 0.4117647 , 0.3372549 ],\n",
       "         [0.5686275 , 0.5686275 , 0.53333336],\n",
       "         ...,\n",
       "         [0.65882355, 0.67058825, 0.65882355],\n",
       "         [0.6784314 , 0.69803923, 0.65882355],\n",
       "         [0.6156863 , 0.6666667 , 0.627451  ]],\n",
       "\n",
       "        [[0.49803922, 0.42745098, 0.3372549 ],\n",
       "         [0.49019608, 0.44313726, 0.37254903],\n",
       "         [0.57254905, 0.5803922 , 0.5529412 ],\n",
       "         ...,\n",
       "         [0.92156863, 0.9254902 , 0.91764706],\n",
       "         [0.9411765 , 0.9490196 , 0.9098039 ],\n",
       "         [0.8235294 , 0.8509804 , 0.8039216 ]],\n",
       "\n",
       "        [[0.5137255 , 0.4509804 , 0.36862746],\n",
       "         [0.5254902 , 0.4862745 , 0.42352942],\n",
       "         [0.5568628 , 0.57254905, 0.54901963],\n",
       "         ...,\n",
       "         [1.        , 0.99607843, 0.9843137 ],\n",
       "         [1.        , 1.        , 0.9647059 ],\n",
       "         [0.8980392 , 0.9098039 , 0.8509804 ]]],\n",
       "\n",
       "\n",
       "       [[[0.7372549 , 0.7411765 , 0.7176471 ],\n",
       "         [0.7529412 , 0.7529412 , 0.73333335],\n",
       "         [0.7529412 , 0.7490196 , 0.7254902 ],\n",
       "         ...,\n",
       "         [0.65882355, 0.65882355, 0.6313726 ],\n",
       "         [0.654902  , 0.64705884, 0.6156863 ],\n",
       "         [0.58431375, 0.5803922 , 0.54509807]],\n",
       "\n",
       "        [[0.7411765 , 0.74509805, 0.7254902 ],\n",
       "         [0.7490196 , 0.7529412 , 0.73333335],\n",
       "         [0.7529412 , 0.7529412 , 0.7372549 ],\n",
       "         ...,\n",
       "         [0.6431373 , 0.64705884, 0.61960787],\n",
       "         [0.6627451 , 0.6509804 , 0.61960787],\n",
       "         [0.56078434, 0.5568628 , 0.52156866]],\n",
       "\n",
       "        [[0.7411765 , 0.74509805, 0.7254902 ],\n",
       "         [0.7490196 , 0.7529412 , 0.7372549 ],\n",
       "         [0.7607843 , 0.7647059 , 0.75686276],\n",
       "         ...,\n",
       "         [0.6509804 , 0.64705884, 0.6117647 ],\n",
       "         [0.654902  , 0.64705884, 0.6117647 ],\n",
       "         [0.60784316, 0.6       , 0.57254905]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7411765 , 0.7372549 , 0.72156864],\n",
       "         [0.7372549 , 0.73333335, 0.7176471 ],\n",
       "         [0.6156863 , 0.6117647 , 0.59607846],\n",
       "         ...,\n",
       "         [0.69803923, 0.6862745 , 0.654902  ],\n",
       "         [0.69411767, 0.68235296, 0.6509804 ],\n",
       "         [0.68235296, 0.67058825, 0.6392157 ]],\n",
       "\n",
       "        [[0.7411765 , 0.7372549 , 0.72156864],\n",
       "         [0.7137255 , 0.70980394, 0.6901961 ],\n",
       "         [0.58431375, 0.5882353 , 0.56078434],\n",
       "         ...,\n",
       "         [0.7019608 , 0.69803923, 0.67058825],\n",
       "         [0.7019608 , 0.7019608 , 0.67058825],\n",
       "         [0.69411767, 0.6901961 , 0.65882355]],\n",
       "\n",
       "        [[0.7490196 , 0.7490196 , 0.73333335],\n",
       "         [0.6862745 , 0.6862745 , 0.67058825],\n",
       "         [0.6156863 , 0.61960787, 0.59607846],\n",
       "         ...,\n",
       "         [0.6862745 , 0.68235296, 0.654902  ],\n",
       "         [0.6901961 , 0.6901961 , 0.65882355],\n",
       "         [0.67058825, 0.6666667 , 0.63529414]]],\n",
       "\n",
       "\n",
       "       [[[0.60784316, 0.5803922 , 0.4745098 ],\n",
       "         [0.654902  , 0.627451  , 0.5058824 ],\n",
       "         [0.654902  , 0.6156863 , 0.4862745 ],\n",
       "         ...,\n",
       "         [0.6745098 , 0.67058825, 0.5411765 ],\n",
       "         [0.6745098 , 0.6745098 , 0.52156866],\n",
       "         [0.68235296, 0.68235296, 0.5372549 ]],\n",
       "\n",
       "        [[0.64705884, 0.60784316, 0.5019608 ],\n",
       "         [0.6862745 , 0.65882355, 0.54509807],\n",
       "         [0.6745098 , 0.6392157 , 0.5176471 ],\n",
       "         ...,\n",
       "         [0.69803923, 0.69411767, 0.5568628 ],\n",
       "         [0.7176471 , 0.72156864, 0.56078434],\n",
       "         [0.7137255 , 0.7176471 , 0.5647059 ]],\n",
       "\n",
       "        [[0.65882355, 0.62352943, 0.49803922],\n",
       "         [0.6745098 , 0.6431373 , 0.5137255 ],\n",
       "         [0.6627451 , 0.627451  , 0.49019608],\n",
       "         ...,\n",
       "         [0.70980394, 0.69803923, 0.5803922 ],\n",
       "         [0.70980394, 0.7019608 , 0.5647059 ],\n",
       "         [0.69803923, 0.69803923, 0.54901963]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5294118 , 0.5137255 , 0.39607844],\n",
       "         [0.5647059 , 0.5372549 , 0.4392157 ],\n",
       "         [0.7058824 , 0.654902  , 0.5803922 ],\n",
       "         ...,\n",
       "         [0.6392157 , 0.6039216 , 0.48235294],\n",
       "         [0.7137255 , 0.6745098 , 0.58431375],\n",
       "         [0.63529414, 0.61960787, 0.49803922]],\n",
       "\n",
       "        [[0.57254905, 0.5294118 , 0.43529412],\n",
       "         [0.6156863 , 0.5803922 , 0.49019608],\n",
       "         [0.6784314 , 0.63529414, 0.56078434],\n",
       "         ...,\n",
       "         [0.654902  , 0.6117647 , 0.5176471 ],\n",
       "         [0.6901961 , 0.654902  , 0.5647059 ],\n",
       "         [0.5921569 , 0.5882353 , 0.45882353]],\n",
       "\n",
       "        [[0.6784314 , 0.61960787, 0.5411765 ],\n",
       "         [0.7058824 , 0.6509804 , 0.5686275 ],\n",
       "         [0.7058824 , 0.65882355, 0.5882353 ],\n",
       "         ...,\n",
       "         [0.57254905, 0.5294118 , 0.45882353],\n",
       "         [0.54509807, 0.50980395, 0.41960785],\n",
       "         [0.57254905, 0.54901963, 0.44313726]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.47058824, 0.3882353 , 0.32156864],\n",
       "         [0.54509807, 0.47843137, 0.40784314],\n",
       "         [0.5882353 , 0.5372549 , 0.4627451 ],\n",
       "         ...,\n",
       "         [0.5568628 , 0.49019608, 0.45490196],\n",
       "         [0.56078434, 0.49411765, 0.4627451 ],\n",
       "         [0.52156866, 0.45490196, 0.42352942]],\n",
       "\n",
       "        [[0.45490196, 0.38039216, 0.30980393],\n",
       "         [0.5803922 , 0.5137255 , 0.44313726],\n",
       "         [0.60784316, 0.54509807, 0.4745098 ],\n",
       "         ...,\n",
       "         [0.58431375, 0.5137255 , 0.48235294],\n",
       "         [0.7254902 , 0.65882355, 0.627451  ],\n",
       "         [0.5764706 , 0.50980395, 0.47843137]],\n",
       "\n",
       "        [[0.54509807, 0.4745098 , 0.40392157],\n",
       "         [0.57254905, 0.5019608 , 0.43529412],\n",
       "         [0.5529412 , 0.47843137, 0.4117647 ],\n",
       "         ...,\n",
       "         [0.5529412 , 0.4862745 , 0.45490196],\n",
       "         [0.5882353 , 0.52156866, 0.49019608],\n",
       "         [0.5764706 , 0.50980395, 0.47843137]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3647059 , 0.3529412 , 0.32941177],\n",
       "         [0.3764706 , 0.3647059 , 0.34117648],\n",
       "         [0.39607844, 0.38039216, 0.35686275],\n",
       "         ...,\n",
       "         [0.47843137, 0.45882353, 0.45882353],\n",
       "         [0.44313726, 0.43137255, 0.4392157 ],\n",
       "         [0.4392157 , 0.4392157 , 0.45490196]],\n",
       "\n",
       "        [[0.39607844, 0.38039216, 0.36862746],\n",
       "         [0.3764706 , 0.36078432, 0.3529412 ],\n",
       "         [0.37254903, 0.35686275, 0.34509805],\n",
       "         ...,\n",
       "         [0.4862745 , 0.4745098 , 0.4745098 ],\n",
       "         [0.43529412, 0.43137255, 0.43529412],\n",
       "         [0.4117647 , 0.41568628, 0.43529412]],\n",
       "\n",
       "        [[0.37254903, 0.35686275, 0.34509805],\n",
       "         [0.35686275, 0.34117648, 0.32941177],\n",
       "         [0.40784314, 0.39215687, 0.38039216],\n",
       "         ...,\n",
       "         [0.4627451 , 0.44705883, 0.44705883],\n",
       "         [0.40392157, 0.4       , 0.40784314],\n",
       "         [0.40392157, 0.40392157, 0.42352942]]],\n",
       "\n",
       "\n",
       "       [[[0.5176471 , 0.5411765 , 0.57254905],\n",
       "         [0.47843137, 0.50980395, 0.5411765 ],\n",
       "         [0.47058824, 0.5137255 , 0.53333336],\n",
       "         ...,\n",
       "         [0.32156864, 0.35686275, 0.38431373],\n",
       "         [0.29411766, 0.3254902 , 0.3764706 ],\n",
       "         [0.34509805, 0.36862746, 0.41568628]],\n",
       "\n",
       "        [[0.6901961 , 0.6901961 , 0.6901961 ],\n",
       "         [0.6784314 , 0.6901961 , 0.69411767],\n",
       "         [0.68235296, 0.70980394, 0.70980394],\n",
       "         ...,\n",
       "         [0.2509804 , 0.28627452, 0.2901961 ],\n",
       "         [0.23921569, 0.25490198, 0.28627452],\n",
       "         [0.2784314 , 0.28627452, 0.30980393]],\n",
       "\n",
       "        [[0.7254902 , 0.70980394, 0.6901961 ],\n",
       "         [0.79607844, 0.8039216 , 0.7882353 ],\n",
       "         [0.7176471 , 0.7490196 , 0.7372549 ],\n",
       "         ...,\n",
       "         [0.3254902 , 0.3647059 , 0.36078432],\n",
       "         [0.3137255 , 0.32941177, 0.34901962],\n",
       "         [0.3372549 , 0.34509805, 0.36078432]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.34117648, 0.40392157, 0.41568628],\n",
       "         [0.4       , 0.48235294, 0.4862745 ],\n",
       "         [0.4117647 , 0.5176471 , 0.5137255 ],\n",
       "         ...,\n",
       "         [0.25490198, 0.24705882, 0.2627451 ],\n",
       "         [0.28627452, 0.27058825, 0.28627452],\n",
       "         [0.31764707, 0.29803923, 0.30980393]],\n",
       "\n",
       "        [[0.30980393, 0.3647059 , 0.3764706 ],\n",
       "         [0.39215687, 0.46666667, 0.4745098 ],\n",
       "         [0.40784314, 0.5058824 , 0.5058824 ],\n",
       "         ...,\n",
       "         [0.35686275, 0.3372549 , 0.3254902 ],\n",
       "         [0.44313726, 0.40392157, 0.40392157],\n",
       "         [0.5254902 , 0.4862745 , 0.4745098 ]],\n",
       "\n",
       "        [[0.33333334, 0.38039216, 0.39607844],\n",
       "         [0.3764706 , 0.44705883, 0.45490196],\n",
       "         [0.4       , 0.49019608, 0.49019608],\n",
       "         ...,\n",
       "         [0.5803922 , 0.54901963, 0.5058824 ],\n",
       "         [0.64705884, 0.5921569 , 0.5647059 ],\n",
       "         [0.64705884, 0.5882353 , 0.5568628 ]]],\n",
       "\n",
       "\n",
       "       [[[0.5294118 , 0.53333336, 0.5529412 ],\n",
       "         [0.7254902 , 0.73333335, 0.7490196 ],\n",
       "         [0.81960785, 0.827451  , 0.8392157 ],\n",
       "         ...,\n",
       "         [0.48235294, 0.49019608, 0.42745098],\n",
       "         [0.52156866, 0.5294118 , 0.47058824],\n",
       "         [0.75686276, 0.7529412 , 0.73333335]],\n",
       "\n",
       "        [[0.44313726, 0.46666667, 0.45490196],\n",
       "         [0.5882353 , 0.6117647 , 0.6039216 ],\n",
       "         [0.6862745 , 0.70980394, 0.7058824 ],\n",
       "         ...,\n",
       "         [0.32941177, 0.3529412 , 0.27058825],\n",
       "         [0.5686275 , 0.5803922 , 0.5137255 ],\n",
       "         [0.7490196 , 0.7490196 , 0.70980394]],\n",
       "\n",
       "        [[0.21176471, 0.2509804 , 0.21960784],\n",
       "         [0.27450982, 0.30980393, 0.29411766],\n",
       "         [0.4       , 0.43529412, 0.43137255],\n",
       "         ...,\n",
       "         [0.28627452, 0.33333334, 0.2509804 ],\n",
       "         [0.45490196, 0.49019608, 0.41568628],\n",
       "         [0.5529412 , 0.5764706 , 0.5137255 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.25490198, 0.26666668, 0.28627452],\n",
       "         [0.27058825, 0.28235295, 0.3019608 ],\n",
       "         [0.25882354, 0.27058825, 0.2901961 ],\n",
       "         ...,\n",
       "         [0.07058824, 0.09019608, 0.09019608],\n",
       "         [0.10196079, 0.1254902 , 0.12941177],\n",
       "         [0.14509805, 0.16470589, 0.1764706 ]],\n",
       "\n",
       "        [[0.26666668, 0.2784314 , 0.29803923],\n",
       "         [0.25882354, 0.27058825, 0.2901961 ],\n",
       "         [0.24705882, 0.25882354, 0.2784314 ],\n",
       "         ...,\n",
       "         [0.07843138, 0.09411765, 0.09411765],\n",
       "         [0.11764706, 0.14117648, 0.14117648],\n",
       "         [0.16078432, 0.18039216, 0.19215687]],\n",
       "\n",
       "        [[0.25490198, 0.26666668, 0.28627452],\n",
       "         [0.24705882, 0.25882354, 0.2784314 ],\n",
       "         [0.24705882, 0.25882354, 0.2784314 ],\n",
       "         ...,\n",
       "         [0.07450981, 0.09411765, 0.09019608],\n",
       "         [0.11764706, 0.14117648, 0.14117648],\n",
       "         [0.18431373, 0.20392157, 0.21568628]]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use data from the example model\n",
    "cnn_x_train\n",
    "cnn_x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9becf",
   "metadata": {},
   "source": [
    "##### The data I will be using will be the same but instead of it being flattened they will retain its 32 by 32 and 3 colour channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d5b603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mslearn-phase2\\msa\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m524,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">591,274</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m591,274\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">591,274</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m591,274\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model initialization\n",
    "CNN_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Building the CNN model\n",
    "CNN_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[32, 32, 3]))\n",
    "CNN_model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "CNN_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "CNN_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "CNN_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "CNN_model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
    "CNN_model.add(tf.keras.layers.Flatten())\n",
    "CNN_model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "CNN_model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# CNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde4348",
   "metadata": {},
   "source": [
    "##### This model has 4 convolutional layers, 2 max pooling layers and 2 dense layers. The activation function is the ReLU for hidden layers, and Softmax for the output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48dbeef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.2682 - loss: 1.9661\n",
      "Epoch 2/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4958 - loss: 1.4042\n",
      "Epoch 3/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.5633 - loss: 1.2268\n",
      "Epoch 4/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.6187 - loss: 1.0831\n",
      "Epoch 5/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.6550 - loss: 0.9736\n",
      "Epoch 6/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.6838 - loss: 0.8918\n",
      "Epoch 7/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.7068 - loss: 0.8317\n",
      "Epoch 8/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7392 - loss: 0.7428\n",
      "Epoch 9/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7575 - loss: 0.6859\n",
      "Epoch 10/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.7830 - loss: 0.6122\n",
      "Epoch 11/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8047 - loss: 0.5529\n",
      "Epoch 12/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8222 - loss: 0.5049\n",
      "Epoch 13/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8403 - loss: 0.4489\n",
      "Epoch 14/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8563 - loss: 0.4064\n",
      "Epoch 15/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.8703 - loss: 0.3614\n",
      "Epoch 16/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.8867 - loss: 0.3171\n",
      "Epoch 17/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9014 - loss: 0.2814\n",
      "Epoch 18/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9071 - loss: 0.2590\n",
      "Epoch 19/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9151 - loss: 0.2321\n",
      "Epoch 20/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9257 - loss: 0.2099\n",
      "Epoch 21/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9258 - loss: 0.2072\n",
      "Epoch 22/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9313 - loss: 0.1888\n",
      "Epoch 23/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9378 - loss: 0.1727\n",
      "Epoch 24/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9427 - loss: 0.1594\n",
      "Epoch 25/25\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.9444 - loss: 0.1552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x299778db7f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model\n",
    "CNN_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model.\n",
    "CNN_model.fit(cnn_x_train, y_train_vec, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570bce5f",
   "metadata": {},
   "source": [
    "##### The categorical cross entropy function is used for multi-class classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b211dfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Making predictions \n",
    "predictions = CNN_model.predict(cnn_x_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Prepare your submission file.\n",
    "CNNsubmission = np.column_stack((id_test, predicted_labels))\n",
    "np.savetxt('CNNsubmission.csv', CNNsubmission, delimiter=',', header='id, Label', comments='', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de7577",
   "metadata": {},
   "source": [
    "##### What could be done to improve this model?\n",
    "- Firstly I could have had more epochs as it seems as if the accuracy was not going to plateau just yet\n",
    "- Implement techniques just as dropout to prevent overfitting\n",
    "- Increase the learning rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
